{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "30-day readmission Bert_500 v2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.3 spark-nlp==3.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjWAOQigGHxT",
        "outputId": "384529ed-e493-4bfb-ef15-c40317c57a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.3\n",
            "  Downloading pyspark-3.1.3.tar.gz (214.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 214.0 MB 7.8 kB/s \n",
            "\u001b[?25hCollecting spark-nlp==3.4.2\n",
            "  Downloading spark_nlp-3.4.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 17.5 MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 47.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.3-py2.py3-none-any.whl size=214463484 sha256=d6cbc18181103717a932ad46fe1078ca2d33a418a8cf7dc6c04c3a60075d2f76\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/8e/49/44c110bb8e008d0778c6577d600d46047c6478ecca3f8f1517\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, spark-nlp, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.3 spark-nlp-3.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "XWrNumHCGPwc",
        "outputId": "aecd1905-7b5a-44e1-dab9-d616a11fd90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.2\n",
            "Apache Spark version:  3.1.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fdc71b5e050>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c609e8bb7f23:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "metadata": {
        "id": "QxUhfeKjGQVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import SQLTransformer\n",
        "from pyspark.ml.feature import StringIndexer"
      ],
      "metadata": {
        "id": "fW4_8-NHGSo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "D7pJ2Q1ZX-y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "t6yrSKNtYFyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f7630d-ab40-4e48-f0c4-37ead6ada72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slicing each document into parts with 1000 (or less) tokens each"
      ],
      "metadata": {
        "id": "ELGYl0ysf_UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test=train_test_split(readmission,test_size=0.5, random_state=49)\n",
        "\n",
        "# sub-sampling the negatives (non-readmitted) on the training set\n",
        "df_train_readm=df_train[df_train.READMISSION_STATUS=='Readmitted']\n",
        "df_train_non_readm=df_train[df_train.READMISSION_STATUS=='Non-readmitted']\n",
        "df_train_sub = pd.concat([df_train_readm, df_train_non_readm.sample(n = len(df_train_readm), random_state = 50)],axis = 1.5)"
      ],
      "metadata": {
        "id": "JU1YGAHrQxnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_sub=df_train_sub.reset_index(drop=True)\n",
        "df_test=df_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "TsV-A1iRRCdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def thousand_split(text):\n",
        "  sublist_list=[]\n",
        "  token_list=text.split(\" \")\n",
        "  if len(token_list)<=1000:\n",
        "    sublist_list.append(text)\n",
        "  else:\n",
        "      num_sublist=int(math.modf(len(token_list)/1000)[1]+1)\n",
        "      sublist_list=[0]*num_sublist\n",
        "      for i in range(num_sublist):\n",
        "          sublist_list[i]=token_list[1000*i:1000*(i+1)]\n",
        "          sublist_list[i]=\" \".join(sublist_list[i])\n",
        "  return(sublist_list)"
      ],
      "metadata": {
        "id": "rYPfhghHRIp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_FILE_THOUSAND=[]\n",
        "HADM_ID=[]\n",
        "READMISSION=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(len(df_train_sub))):\n",
        "  sublist_list=thousand_split(df_train_sub['TEXT_FILE'][i])\n",
        "  admission_id=df_train_sub['HADM_ID'][i]\n",
        "  readmission_status=df_train_sub['READMISSION_STATUS'][i]\n",
        "  for sublist in sublist_list:\n",
        "    TEXT_FILE_thousand.append(sublist)\n",
        "    HADM_ID.append(admission_id)\n",
        "    READMISSION.append(readmission_status)"
      ],
      "metadata": {
        "id": "8WjirRxkRSlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_sliced= pd.DataFrame(list(zip(HADM_ID,TEXT_FILE_thousand,READMISSION)),\n",
        "               columns =['HADM_ID','TEXT_FILE','readmission_status'])"
      ],
      "metadata": {
        "id": "A0InuRHQRj1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_FILE_thousand=[]\n",
        "HADM_ID=[]\n",
        "READMISSION=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(len(df_test))):\n",
        "  sublist_list=thousand_split(df_test['TEXT_FILE'][i])\n",
        "  admission_id=df_test['HADM_ID'][i]\n",
        "  readmission_status=df_test['READMISSION_STATUS'][i]\n",
        "  for sublist in sublist_list:\n",
        "    TEXT_FILE_thousand.append(sublist)\n",
        "    HADM_ID.append(admission_id)\n",
        "    READMISSION.append(readmission_status)"
      ],
      "metadata": {
        "id": "fXJMzmcYRtU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_sliced= pd.DataFrame(list(zip(HADM_ID,TEXT_FILE_thousand,READMISSION)),\n",
        "               columns =['HADM_ID','TEXT_FILE','readmission_status'])"
      ],
      "metadata": {
        "id": "8wmKUaNuR_am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"arrow.enabling\", \"true\")\n",
        "train = spark.createDataFrame(df_train_sliced)\n",
        "test= spark.createDataFrame(df_test_sliced)"
      ],
      "metadata": {
        "id": "tzxpV3G-SHUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PIPELINES"
      ],
      "metadata": {
        "id": "S-nprxmOSlq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Produce pipeline for data cleaning and sentence(discharge summary) embedding\n",
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"TEXT_FILE\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"gdrive/MyDrive/Colab_notebook/lemma.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "bert_embeddings = BertEmbeddings.pretrained()\\\n",
        "  .setInputCols([\"document\",\"lemma\"])\\\n",
        "  .setOutputCol(\"bert_embeddings\")\\\n",
        "  .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"bert_embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "      .setInputCols([\"sentence_embeddings\"]) \\\n",
        "      .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "explodeVectors = SQLTransformer(statement=\n",
        "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"readmission_status\", outputCol = \"label\")\n",
        "\n",
        "nlp_pipeline_Bert = Pipeline(\n",
        "stages=[document_assembler, \n",
        "          tokenizer,\n",
        "          lemmatizer,\n",
        "          bert_embeddings,\n",
        "          embeddingsSentence,\n",
        "          embeddings_finisher,\n",
        "          explodeVectors,\n",
        "          label_stringIdx])"
      ],
      "metadata": {
        "id": "RaP9QgybSa_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_bert_thousand=nlp_pipeline_Bert.fit(train)"
      ],
      "metadata": {
        "id": "kwZ5mdFrTNED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_bert_thousand.write().overwrite().save('gdrive/MyDrive/Colab_notebook/Models_Pipelines/bert_1000_readmission')"
      ],
      "metadata": {
        "id": "Y_ZX_sM1TRWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "nlp_bert_five_hund= PipelineModel.load(\"gdrive/MyDrive/Colab_notebook/Models_Pipelines/bert_1000_readmission/\")"
      ],
      "metadata": {
        "id": "ShaRXUrFTe4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train=nlp_bert_thousand.transform(train)\n",
        "processed_test=nlp_bert_thousand.transform(test)"
      ],
      "metadata": {
        "id": "hz4Zbg05Tkn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining Rows\n",
        "from pyspark.sql.functions import collect_list\n",
        "from pyspark.sql import functions as F\n",
        "processed_train_combined = processed_train.groupby('HADM_ID').agg(collect_list('features').alias(\"features\"),F.min(processed_train.label))\n",
        "processed_test_combined= processed_test.groupby('HADM_ID').agg(collect_list('features').alias(\"features\"),F.min(processed_test.label))"
      ],
      "metadata": {
        "id": "Jp6hzRhRTxZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saved as orc\n",
        "processed_train_combined.write.orc(\"gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_train\")\n",
        "processed_test_combined.write.orc(\"gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_test\")"
      ],
      "metadata": {
        "id": "GdJqfa3lUMv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing average embedding vector\n",
        "def average_emb(df):\n",
        "  for i in range(len(df)):\n",
        "    new_embedding_list=[]\n",
        "    embedding_list=df['features'][i]\n",
        "    for k in range(len(embedding_list)):\n",
        "      sentence_embedding=embedding_list[k]\n",
        "      new_embedding_list.append(sentence_embedding)\n",
        "    df['features'][i]=[sum(sub_list) / len(sub_list) for sub_list in zip(*new_embedding_list)]\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "IERqYQh0UTYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_combined=spark.read.orc(\"gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_train\")\n",
        "processed_test_combined=spark.read.orc(\"gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_test\")"
      ],
      "metadata": {
        "id": "mLf5azqGHLHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train=processed_train_combined.toPandas()"
      ],
      "metadata": {
        "id": "RnH5ooejL4SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_test=processed_test_combined.toPandas()"
      ],
      "metadata": {
        "id": "Xu-xDB74L_-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train.head()"
      ],
      "metadata": {
        "id": "jGtqvc_NIDAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train.label=pd_train['min(label)'].astype(\"int\")\n",
        "pd_test.label=pd_test['min(label)'].astype(\"int\")"
      ],
      "metadata": {
        "id": "k3knwLuTSxbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_to_sep(df):\n",
        "  HADM_ID=[]\n",
        "  features=[]\n",
        "  label=[]\n",
        "  for i in range(len(df)):\n",
        "    embedding_list=df['features'][i]\n",
        "    for n in range(len(embedding_list)):\n",
        "      single_embedding=embedding_list[n]\n",
        "      HADM_ID.append(df['HADM_ID'][i])\n",
        "      features.append(single_embedding[3])\n",
        "      label.append(df['min(label)'][i])\n",
        "  df_sep= pd.DataFrame(list(zip(HADM_ID,features,label)),\n",
        "               columns =['HADM_ID','features','label'])\n",
        "  return(df_sep)"
      ],
      "metadata": {
        "id": "loLxoMeQJN45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train_sep=combined_to_sep(pd_train)\n",
        "pd_test_sep=combined_to_sep(pd_test)"
      ],
      "metadata": {
        "id": "RzWFwyp9MU-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train_sep.to_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_train_v2.csv')\n",
        "pd_test_sep.to_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_test_v2.csv')"
      ],
      "metadata": {
        "id": "dmrVp4pN5lCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train_sep=pd.read_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_train_v2.csv')\n",
        "pd_test_sep=pd.read_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_1000_test_v2.csv')"
      ],
      "metadata": {
        "id": "K2zfJ9zcalUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop invalid rows where features='[]'\n",
        "train_invalid_index=[]\n",
        "for i in range(len(pd_train_sep)):\n",
        "  if pd_train_sep['features'][i]=='[]':\n",
        "    train_invalid_index.append(i)\n",
        "pd_train_sep=pd_train_sep.drop(train_invalid_index).reset_index(drop=True)\n",
        "\n",
        "test_invalid_index=[]\n",
        "for i in range(len(pd_test_sep)):\n",
        "  if pd_test_sep['features'][i]=='[]':\n",
        "    test_invalid_index.append(i)\n",
        "pd_test_sep=pd_test_sep.drop(test_invalid_index).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "BU51YrD1VMnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "sUN0nxU0Chxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "SYWGmHN7lacL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pd_train_sep.features\n",
        "y_train=pd_train_sep.label\n",
        "X_train_trans=[]\n",
        "for doc in X_train:\n",
        "  embedding=doc[1:-1]\n",
        "  embedding_list=embedding.split(\",\")\n",
        "  str_to_num_list=[]\n",
        "  for num_str in embedding_list:\n",
        "    str_to_num_list.append(float(num_str))\n",
        "  X_train_trans.append(str_to_num_list)"
      ],
      "metadata": {
        "id": "cjHPj8RVBays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=pd_test_sep.features\n",
        "y_test=pd_test_sep.label\n",
        "X_test_trans=[]\n",
        "for doc in X_test:\n",
        "  embedding=doc[1:-1]\n",
        "  embedding_list=embedding.split(\",\")\n",
        "  str_to_num_list=[]\n",
        "  for num_str in embedding_list:\n",
        "    str_to_num_list.append(float(num_str))\n",
        "  X_test_trans.append(str_to_num_list)"
      ],
      "metadata": {
        "id": "vuN1nlheAExc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual division\n",
        "subset_1=pd_train_sep.iloc[0:2201]\n",
        "subset_2=pd_train_sep.iloc[2201:4401]\n",
        "subset_3=pd_train_sep.iloc[4401:6602]\n",
        "subset_4=pd_train_sep.iloc[6602:8802]\n",
        "subset_5=pd_train_sep.iloc[8802:]"
      ],
      "metadata": {
        "id": "3SE8nZav-B-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "# Write hyper-parameter tuning from scratch so that parameter k can also be tunned\n",
        "subset_list=[subset_1,subset_2,subset_3,subset_4,subset_5]\n",
        "solvers_list=['newton-cg', 'lbfgs', 'liblinear']\n",
        "c_values_list = [1.0, 0.1, 0.01]\n",
        "k_list=[0.01,0.05,0.1,0.15]\n",
        "solver_result=[]\n",
        "c_values_result=[]\n",
        "k_list_result=[]\n",
        "auc_score=[]\n",
        "for i in range(len(subset_list)):\n",
        "  val_set=subset_list[i]\n",
        "  training_set=pd.concat(subset_list[:i]+subset_list[i+1:])\n",
        "  X_train=training_set.features\n",
        "  y_train=training_set.label\n",
        "  X_val=val_set.features\n",
        "  y_val=val_set.label\n",
        "  X_train_trans=[]\n",
        "  for doc in X_train:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "      str_to_num_list.append(float(num_str))\n",
        "    X_train_trans.append(str_to_num_list)\n",
        "  X_val_trans=[]\n",
        "  for doc in X_val:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "      str_to_num_list.append(float(num_str))\n",
        "    X_val_trans.append(str_to_num_list)\n",
        "  for s in solvers_list:\n",
        "    for c in c_values_list:\n",
        "      for k in k_list:\n",
        "        logistic_clf_bert=LogisticRegression(solver=s,C=c)\n",
        "        logistic_clf_bert.fit(X_train_trans,y_train)\n",
        "        y_pred=logistic_clf_bert.predict_proba(X_val_trans)\n",
        "        ID_PRED=pd.DataFrame()\n",
        "        ID_PRED['HADM_ID']=val_set['HADM_ID']\n",
        "        ID_PRED['pred']=y_pred[:,1]\n",
        "        ID_PRED['actual']=y_val\n",
        "        re_combined=ID_PRED.groupby('HADM_ID',as_index=False,sort=False).agg({'pred':['mean','max','count'],'actual':'mean'})\n",
        "        re_combined.columns=['HADM_ID','pred_mean','pred_max','pred_count','actual']\n",
        "        re_combined['final_prediction']=(re_combined['pred_max']+re_combined['pred_mean']*re_combined['pred_count']/k)/(1+re_combined['pred_count']/k)\n",
        "        new_auc=roc_auc_score(re_combined['actual'],re_combined['final_prediction'])\n",
        "        solver_result.append(s)\n",
        "        c_values_result.append(c)\n",
        "        k_list_result.append(k)\n",
        "        auc_score.append(new_auc)\n",
        "  df_results=pd.DataFrame(list(zip(solver_result, c_values_result,k_list_result,auc_score)),columns=['solver','c','k','auc'])\n",
        "  result_groupby=df_results.groupby(['solver','c','k'],as_index=False,sort=False).agg({'auc':'mean'})\n",
        "  result_groupby.columns=['solver','c','k','auc_mean']\n",
        "  result_groupby=result_groupby.sort_values(by='auc_mean',ascending=False)\n",
        "result_groupby"
      ],
      "metadata": {
        "id": "Y3glzjLnA3dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_clf_bert=LogisticRegression(solver='newton-cg',C=0.5)\n",
        "logistic_clf_bert.fit(X_train_trans,y_train)\n",
        "y_pred_logistic_clf_bert=logistic_clf_bert.predict_proba(X_test_trans)"
      ],
      "metadata": {
        "id": "YIoxMcabau8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID_PRED=pd.DataFrame()\n",
        "ID_PRED['HADM_ID']=pd_test_sep['HADM_ID']\n",
        "ID_PRED['pred']=y_pred_logistic_clf_bert[:,1]\n",
        "ID_PRED['actual']=y_test\n",
        "re_combined=ID_PRED.groupby('HADM_ID',as_index=False,sort=False).agg({'pred':['mean','max','count'],'actual':'mean'})\n",
        "re_combined.columns=['HADM_ID','pred_mean','pred_max','pred_count','actual']\n",
        "re_combined['final_prediction']=(re_combined['pred_max']+re_combined['pred_mean']*re_combined['pred_count']/0.01)/(1+re_combined['pred_count']/0.01)\n",
        "auc_logistic_clf_bert=roc_auc_score(re_combined['actual'],re_combined['final_prediction'])"
      ],
      "metadata": {
        "id": "SmYan_G6Buw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "# Write hyper-parameter tuning from scratch so that parameter k can also be tunned\n",
        "subset_list=[subset_1,subset_2,subset_3,subset_4,subset_5]\n",
        "max_depth=[5, 10, 15]\n",
        "min_samples_leaf=[20, 50, 100]\n",
        "criterion=[\"gini\", \"entropy\"]\n",
        "n_estimators=[10,50,100]\n",
        "k_list=[0.01,0.05,0.1]\n",
        "max_depth_result=[]\n",
        "min_samples_leaf_result=[]\n",
        "criterion_result=[]\n",
        "n_estimators_result=[]\n",
        "k_list_result=[]\n",
        "auc_score=[]\n",
        "for i in range(len(subset_list)):\n",
        "  val_set=subset_list[i]\n",
        "  training_set=pd.concat(subset_list[:i]+subset_list[i+1:])\n",
        "  X_train=training_set.features\n",
        "  y_train=training_set.label\n",
        "  X_val=val_set.features\n",
        "  y_val=val_set.label\n",
        "  X_train_trans=[]\n",
        "  for doc in X_train:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "      str_to_num_list.append(float(num_str))\n",
        "    X_train_trans.append(str_to_num_list)\n",
        "  X_val_trans=[]\n",
        "  for doc in X_val:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "      str_to_num_list.append(float(num_str))\n",
        "    X_val_trans.append(str_to_num_list)\n",
        "  for depth in max_depth:\n",
        "    for leaf in min_samples_leaf:\n",
        "      for criter in criterion:\n",
        "        for estimator in n_estimators:\n",
        "          for k in k_list:\n",
        "            rb_clf_bert=RandomForestClassifier(max_depth=depth,min_samples_leaf=leaf,criterion=criter,n_estimators=estimator)\n",
        "            rb_clf_bert.fit(X_train_trans,y_train)\n",
        "            y_pred=rb_clf_bert.predict_proba(X_val_trans)\n",
        "            ID_PRED=pd.DataFrame()\n",
        "            ID_PRED['HADM_ID']=val_set['HADM_ID']\n",
        "            ID_PRED['pred']=y_pred[:,1]\n",
        "            ID_PRED['actual']=y_val\n",
        "            re_combined=ID_PRED.groupby('HADM_ID',as_index=False,sort=False).agg({'pred':['mean','max','count'],'actual':'mean'})\n",
        "            re_combined.columns=['HADM_ID','pred_mean','pred_max','pred_count','actual']\n",
        "            re_combined['final_prediction']=(re_combined['pred_max']+re_combined['pred_mean']*re_combined['pred_count']/k)/(1+re_combined['pred_count']/k)\n",
        "            new_auc=roc_auc_score(re_combined['actual'],re_combined['final_prediction'])\n",
        "            max_depth_result.append(depth)\n",
        "            min_samples_leaf_result.append(leaf)\n",
        "            criterion_result.append(criter)\n",
        "            n_estimators_result.append(estimator)\n",
        "            k_list_result.append(k)\n",
        "            auc_score.append(new_auc)\n",
        "    df_results=pd.DataFrame(list(zip(max_depth_result, min_samples_leaf_result,criterion_result,n_estimators_result,k_list_result,auc_score)),columns=['max_depth','min_samples_leaf','criterion','n_estimator','k','auc'])\n",
        "    result_groupby=df_results.groupby(['max_depth','min_samples_leaf','criterion','n_estimator','k'],as_index=False,sort=False).agg({'auc':'mean'})\n",
        "    result_groupby.columns=['max_depth','min_samples_leaf','criterion','n_estimator','k','auc_mean']\n",
        "    result_groupby=result_groupby.sort_values(by='auc_mean',ascending=False)\n",
        "result_groupby"
      ],
      "metadata": {
        "id": "q9eWdVH9qNyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rb_clf_bert=RandomForestClassifier(max_depth=7,min_samples_leaf=7,criterion='gini',n_estimators=10)\n",
        "rb_clf_bert.fit(X_train_trans,y_train)\n",
        "y_pred_rb_clf_bert=rb_clf_bert.predict_proba(X_test_trans)"
      ],
      "metadata": {
        "id": "Y5ml3HQAz66H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID_PRED=pd.DataFrame()\n",
        "ID_PRED['HADM_ID']=pd_test_sep['HADM_ID']\n",
        "ID_PRED['pred']=y_pred_rb_clf_bert[:,1]\n",
        "ID_PRED['actual']=y_test\n",
        "re_combined=ID_PRED.groupby('HADM_ID',as_index=False,sort=False).agg({'pred':['mean','max','count'],'actual':'mean'})\n",
        "re_combined.columns=['HADM_ID','pred_mean','pred_max','pred_count','actual']\n",
        "re_combined['final_prediction']=(re_combined['pred_max']+re_combined['pred_mean']*re_combined['pred_count']/0.05)/(1+re_combined['pred_count']/0.05)\n",
        "auc_rb_clf_bert=roc_auc_score(re_combined['actual'],re_combined['final_prediction'])"
      ],
      "metadata": {
        "id": "Cuhl8QHU0dNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM-linear\n",
        "subset_list=[subset_1,subset_2,subset_3,subset_4,subset_5]\n",
        "c_values_list = [100,10,1.0,0.1,0.01]\n",
        "k_list=[0.01,0.05,0.1,0.15]\n",
        "c_values_result=[]\n",
        "k_list_result=[]\n",
        "auc_score=[]\n",
        "for i in range(len(subset_list)):\n",
        "  val_set=subset_list[i]\n",
        "  training_set=pd.concat(subset_list[:i]+subset_list[i+1:])\n",
        "  X_train=training_set.features\n",
        "  y_train=training_set.label\n",
        "  X_val=val_set.features\n",
        "  y_val=val_set.label\n",
        "  X_train_trans=[]\n",
        "  for doc in X_train:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "      str_to_num_list.append(float(num_str))\n",
        "    X_train_trans.append(str_to_num_list)\n",
        "  X_val_trans=[]\n",
        "  for doc in X_val:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "      str_to_num_list.append(float(num_str))\n",
        "    X_val_trans.append(str_to_num_list)\n",
        "  for c in c_values_list:\n",
        "    for k in k_list:\n",
        "      lsvm_clf_bert=LinearSVC(C=c)\n",
        "      lsvm_clf_bert.fit(X_train_trans,y_train)\n",
        "      y_pred=lsvm_clf_bert.decision_function(X_val_trans)\n",
        "      ID_PRED=pd.DataFrame()\n",
        "      ID_PRED['HADM_ID']=val_set['HADM_ID']\n",
        "      ID_PRED['pred']=y_pred\n",
        "      ID_PRED['actual']=y_val\n",
        "      re_combined=ID_PRED.groupby('HADM_ID',as_index=False,sort=False).agg({'pred':['mean','max','count'],'actual':'mean'})\n",
        "      re_combined.columns=['HADM_ID','pred_mean','pred_max','pred_count','actual']\n",
        "      re_combined['final_prediction']=(re_combined['pred_max']+re_combined['pred_mean']*re_combined['pred_count']/k)/(1+re_combined['pred_count']/k)\n",
        "      new_auc=roc_auc_score(re_combined['actual'],re_combined['final_prediction'])\n",
        "      c_values_result.append(c)\n",
        "      k_list_result.append(k)\n",
        "      auc_score.append(new_auc)\n",
        "  df_results=pd.DataFrame(list(zip(c_values_result,k_list_result,auc_score)),columns=['c','k','auc'])\n",
        "  result_groupby=df_results.groupby(['c','k'],as_index=False,sort=False).agg({'auc':'mean'})\n",
        "  result_groupby.columns=['c','k','auc_mean']\n",
        "  result_groupby=result_groupby.sort_values(by='auc_mean',ascending=False)\n",
        "result_groupby"
      ],
      "metadata": {
        "id": "tVV-Ep8p1CnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsvm_clf_bert=LinearSVC(C=0.05)\n",
        "lsvm_clf_bert.fit(X_train_trans,y_train)\n",
        "y_pred_lsvm_clf_bert=lsvm_clf_bert.decision_function(X_test_trans)"
      ],
      "metadata": {
        "id": "Pn7x-Bxifto2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID_PRED=pd.DataFrame()\n",
        "ID_PRED['HADM_ID']=pd_test_sep['HADM_ID']\n",
        "ID_PRED['pred']=y_pred_lsvm_clf_bert\n",
        "ID_PRED['actual']=y_test\n",
        "re_combined=ID_PRED.groupby('HADM_ID',as_index=False,sort=False).agg({'pred':['mean','max','count'],'actual':'mean'})\n",
        "re_combined.columns=['HADM_ID','pred_mean','pred_max','pred_count','actual']\n",
        "re_combined['final_prediction']=(re_combined['pred_max']+re_combined['pred_mean']*re_combined['pred_count']/0.05)/(1+re_combined['pred_count']/0.05)\n",
        "auc_lsvm_clf_bert=roc_auc_score(re_combined['actual'],re_combined['final_prediction'])"
      ],
      "metadata": {
        "id": "LU1kZ355gK5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}