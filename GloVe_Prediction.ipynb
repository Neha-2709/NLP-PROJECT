{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEJBCDGIOkbVjJ09Mfabmg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee1j63BGtgXQ"
      },
      "outputs": [],
      "source": [
        "! pip install -q pyspark==3.1.3 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd C:\\Users\\NEHA\\nlp_project\\"
      ],
      "metadata": {
        "id": "85lmHGJptjUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZjOoh1UotjW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import SQLTransformer\n",
        "from pyspark.ml.feature import StringIndexer"
      ],
      "metadata": {
        "id": "2AhdC7EvtjZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NbZ7oMSotjcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "ai6fqAGktje7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readmission=pd.read_csv('NOT_CLEANED.csv')"
      ],
      "metadata": {
        "id": "a2U5N_4Stjhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test=train_test_split(readmission,test_size=0.2, random_state=42)\n",
        "\n",
        "df_train_readm=df_train[df_train.READMISSION_STATUS=='Readmitted']\n",
        "df_train_non_readm=df_train[df_train.READMISSION_STATUS=='Non-readmitted']\n",
        "df_train_sub = pd.concat([df_train_readm, df_train_non_readm.sample(n = len(df_train_readm), random_state = 45)],axis = 0.5)\n",
        "# Convert the pandas df to a spark df\n",
        "spark.conf.set(\"enabled.arrow\", \"true\")\n",
        "train = spark.createDataFrame(df_train_sub)\n",
        "test= spark.createDataFrame(df_test)"
      ],
      "metadata": {
        "id": "eQsD0buGtjj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Produce pipeline for data cleaning and sentence(discharge summary) embedding\n",
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"TEXT_AGG\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'lemma'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    embeddings_finisher = EmbeddingsFinisher() \\\n",
        "      .setInputCols([\"sentence_embeddings\"]) \\\n",
        "      .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "explodeVectors = SQLTransformer(statement=\n",
        "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"READMISSION_STATUS\", outputCol = \"label\")\n",
        "\n",
        "nlp_pipeline_GloVe = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner,\n",
        "            lemmatizer,\n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher,\n",
        "            explodeVectors,\n",
        "            label_stringIdx])"
      ],
      "metadata": {
        "id": "etUzvD4Ztjnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "glove_readmission= PipelineModel.load(\"/Models_Pipelines/glove_readmission\")\n",
        "\n",
        "# Transform training set\n",
        "processed_GloVe=glove_readmission.transform(train)"
      ],
      "metadata": {
        "id": "6zMbwVFAubZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_GloVe.select('TEXT_AGG','features','label').show(truncate=40)"
      ],
      "metadata": {
        "id": "pHLnUNgWubb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train=processed_GloVe.select('features','label').toPandas()"
      ],
      "metadata": {
        "id": "g6lQlyzHubfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_test=processed_GloVe_test.select('features','label').toPandas()"
      ],
      "metadata": {
        "id": "iEyhI938ubh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train.to_csv(\"Glove_train.csv\")\n",
        "pd_test.to_csv(\"glove_test.csv\")\n",
        "pd_train.label=pd_train.label.astype(\"int\")\n",
        "pd_test.label=pd_test.label.astype(\"int\")\n",
        "pd_train=pd.read_csv(\"Glove_train.csv\")\n",
        "pd_test=pd.read_csv(\"glove_test.csv\")"
      ],
      "metadata": {
        "id": "UGUzS_L-ubkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pd_train.features\n",
        "y_train=pd_train.label\n",
        "X_test=pd_test.features\n",
        "y_test=pd_test.label"
      ],
      "metadata": {
        "id": "I2WPWjyNuboJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trans=[]\n",
        "for doc in X_train:\n",
        "    embedding=doc[2:-2]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "        str_to_num_list.append(float(num_str))\n",
        "    X_train_trans.append(str_to_num_list)"
      ],
      "metadata": {
        "id": "DzW7dhN0vLdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_trans=[]\n",
        "for doc in X_test:\n",
        "    embedding=doc[2:-2]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "        str_to_num_list.append(float(num_str))\n",
        "    X_test_trans.append(str_to_num_list)"
      ],
      "metadata": {
        "id": "zeatCLi1vLsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Glove=[]\n",
        "Roc_auc_cv=[]\n",
        "Roc_auc_test=[]"
      ],
      "metadata": {
        "id": "Zkh_YN9dvL3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "UinvA3qqv3Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "EF40Uxm0vMBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "param= dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scoring='roc_auc'\n",
        "\n",
        "logistic_clf_glove = BayesSearchCV(estimator=LogisticRegression(), search_spaces=param, scoring=scoring, n_jobs=-1, cv=cv)\n",
        "logistic_clf_glove.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "hVvzV6wfvMPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/Models_Pipelines/logistic_glove.pkl','wb') as f:\n",
        "    pickle.dump(logistic_glove,f)"
      ],
      "metadata": {
        "id": "WrJZJIKUvMXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/Models_Pipelines/logistic_glove.pkl', 'rb') as f:\n",
        "    logistic_glove = pickle.load(f)\n",
        "logistic_glove_best=logistic_glove.best_score_\n",
        "logistic_glove_best"
      ],
      "metadata": {
        "id": "Zg5iUkB9wU-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Glove.append(\"Logistic Regression\")\n",
        "Roc_auc_cv.append(logistic_glove_best)\n",
        "Roc_auc_test.append(roc_auc_y_prob_logistic_glove)"
      ],
      "metadata": {
        "id": "Fopl4KEAwVK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "QY-YUnk2wo9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "max_depth=[2, 3, 5, 10, 20]\n",
        "min_samples_leaf=[5, 10, 20, 50, 100]\n",
        "criterion=[\"gini\", \"entropy\"]\n",
        "\n",
        "param= dict(max_depth=max_depth,min_samples_leaf=min_samples_leaf,criterion=criterion)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scoring='roc_auc'\n",
        "\n",
        "dec_tree_clf_glove = BayesSearchCV(estimator=DecisionTreeClassifier(), search_spaces=param, scoring=scoring, n_jobs=-1, cv=cv)"
      ],
      "metadata": {
        "id": "-lm8uDdqwVNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_tree_glove.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "DPrOBsTwwVQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/Models_Pipelines/dec_tree_glove.pkl','wb') as f:\n",
        "    pickle.dump(dec_tree_glove,f)\n",
        "with open('/Models_Pipelines/dec_tree_glove.pkl', 'rb') as f:\n",
        "    dec_tree_glove = pickle.load(f)\n",
        "dec_tree_glove_best=dec_tree_glove.best_score_\n",
        "dec_tree_glove_best"
      ],
      "metadata": {
        "id": "EZrmGiufwVSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Glove.append(\"Decision Tree\")\n",
        "Roc_auc_cv.append(dec_tree_glove_best)\n",
        "Roc_auc_test.append(roc_auc_dec_tree_glove)"
      ],
      "metadata": {
        "id": "e3qzcXhfwVU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "L_KyOGILw8-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_values=[100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "param= dict(C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scoring='roc_auc'\n",
        "\n",
        "lsvc_clf_glove = BayesSearchCV(estimator=LinearSVC(), search_spaces=param, scoring=scoring, n_jobs=-1, cv=cv)\n",
        "lsvc_clf_glove.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "pc8HC4ytwVYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/Models_Pipelines/lsvc_glove.pkl','wb') as f:\n",
        "    pickle.dump(lsvc_glove,f)\n",
        "with open('/Models_Pipelines/lsvc_glove.pkl', 'rb') as f:\n",
        "    lsvc_glove = pickle.load(f)\n",
        "lsvc_glove_best=lsvc_glove.best_score_\n",
        "lsvc_glove_best"
      ],
      "metadata": {
        "id": "nzpGue7hxAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dec_func_lsvc_glove=lsvc_glove.decision_function(X_test_trans)\n",
        "roc_auc_lsvc_glove=roc_auc_score(y_test, y_dec_func_lsvc_glove)\n",
        "roc_auc_lsvc_glove"
      ],
      "metadata": {
        "id": "n4e9FrOixAwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "6fBoDZBxxWkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "max_depth=[5, 10, 15, 20]\n",
        "min_samples_leaf=[5, 10, 20, 50, 100]\n",
        "criterion=[\"gini\", \"entropy\"]\n",
        "n_estimators=[10,50,100,150]\n",
        "\n",
        "param= dict(max_depth=max_depth,min_samples_leaf=min_samples_leaf,criterion=criterion,n_estimators=n_estimators)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scoring='roc_auc'\n",
        "\n",
        "rand_for_glove = BayesSearchCV(estimator=RandomForestClassifier(), search_spaces=param, scoring=scoring, n_jobs=-1, cv=cv)\n",
        "rand_for_glove.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "DsIfIti9xAy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/Models_Pipelines/rand_for_glove.pkl','wb') as f:\n",
        "    pickle.dump(rand_for_glove,f)\n",
        "with open('/Models_Pipelines/rand_for_glove.pkl', 'rb') as f:\n",
        "    rand_for_glove = pickle.load(f)\n",
        "rand_for_glove_best=rand_for_glove.best_score_\n",
        "rand_for_glove_best"
      ],
      "metadata": {
        "id": "ym9lT65qxA11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob_rand_for_glove = rand_for_glove.predict_proba(X_test_trans)\n",
        "roc_auc_rand_for_glove=roc_auc_score(y_test,y_prob_rand_for_glove[:,1])\n",
        "roc_auc_rand_for_glove"
      ],
      "metadata": {
        "id": "n-KnsfstxA5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Glove.append(\"Random Forest\")\n",
        "Roc_auc_cv.append(rand_for_glove_best)\n",
        "Roc_auc_test.append(roc_auc_rand_for_glove)\n",
        "result_Glove=pd.DataFrame({'model_GloVe': model_Glove, 'Roc_auc_cross_val': Roc_auc_cv,'Roc_auc_test':Roc_auc_test})\n",
        "result_Glove=result_Glove.sort_values('Roc_auc_test')\n",
        "result_Glove.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "uB02DlpFyoxT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}